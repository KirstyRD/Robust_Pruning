cp: cannot stat ‘checkpoint_CIFAR100_resnet50_100_100_0.0_RobustnessDandR_eps1=7.8,_eps2=2.9__7552_107374182397200_100.000000.weights’: No such file or directory
Traceback (most recent call last):
  File "main_gc.py", line 1159, in <module>
    main()
  File "main_gc.py", line 1120, in main
    num_left, new_iter = train(args, model, device, train_loader, optimizer, epoch, criterion, oracle, test_loader_constr, test_loader_adv, print_iter, starttime, pruning_settings, train_writer=train_writer, pruning_engine=pruning_engine)
  File "main_gc.py", line 157, in train
    _, dl2_batch_loss, constr_acc = oracle.evaluate(x_batches, y_batches, None, args)
  File "/home/kduncan/Pruning/oracles.py", line 65, in evaluate
    neg_losses, pos_losses, sat, _ = self.constraint.loss(x_batches, y_batches, z_batches, args)
  File "/home/kduncan/Pruning/constraints.py", line 49, in loss
    constr = self.get_condition(z_inp, z_out, x_batches, y_batches)
  File "/home/kduncan/Pruning/constraints.py", line 352, in get_condition
    x_out1, x_out2 = self.net(x_batches[0]), self.net(x_batches[1])
  File "/home/kduncan/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/kduncan/Pruning/models/resnet.py", line 192, in forward
    x = self.layer2(x)
  File "/home/kduncan/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/kduncan/.local/lib/python3.6/site-packages/torch/nn/modules/container.py", line 92, in forward
    input = module(input)
  File "/home/kduncan/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/kduncan/Pruning/models/resnet.py", line 107, in forward
    out = self.conv3(out)
  File "/home/kduncan/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/kduncan/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 343, in forward
    return self.conv2d_forward(input, self.weight)
  File "/home/kduncan/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 340, in conv2d_forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 154.00 MiB (GPU 0; 4.63 GiB total capacity; 4.09 GiB already allocated; 153.94 MiB free; 61.14 MiB cached)
Files already downloaded and verified
Files already downloaded and verified
Ignoring network_output argument, using prob and logprob to obtain KL divergence
CIFAR100_resnet50_1_1_0.01_RobustnessDandR_eps1=7.8,_eps2=2.9__128
main_gc.py --dataset=CIFAR100 --model=resnet50 --pruning=True --tensorboard=True --log-interval=1 --pruning_config=./configs/CIFAR100_1_1.json --constraint=RobustnessDandR(eps1=7.8, eps2=2.9) --print-after-epoch=0 --dl2-weight=0.01 --delay=0 --epochs=1000 --adv-after-epoch=10 --batch-size=128 --load_model=./CIFAR100/cifar100_resnet50_best.weights --name=CIFAR100_resnet50_16
pruning_engine.load_mask(): did not find mask file, will load nothing
=> loading checkpoint './CIFAR100/cifar100_resnet50_best.weights'
conv1.weight torch.Size([64, 3, 3, 3])
bn1.weight torch.Size([64])
bn1.bias torch.Size([64])
bn1.running_mean torch.Size([64])
bn1.running_var torch.Size([64])
bn1.num_batches_tracked torch.Size([])
layer1.0.conv1.weight torch.Size([64, 64, 1, 1])
layer1.0.bn1.weight torch.Size([64])
layer1.0.bn1.bias torch.Size([64])
layer1.0.bn1.running_mean torch.Size([64])
layer1.0.bn1.running_var torch.Size([64])
*********
conv1.weight torch.Size([64, 3, 3, 3])
bn1.weight torch.Size([64])
bn1.bias torch.Size([64])
bn1.running_mean torch.Size([64])
bn1.running_var torch.Size([64])
bn1.num_batches_tracked torch.Size([])
layer1.0.conv1.weight torch.Size([64, 64, 1, 1])
layer1.0.bn1.weight torch.Size([64])
layer1.0.bn1.bias torch.Size([64])
layer1.0.bn1.running_mean torch.Size([64])
layer1.0.bn1.running_var torch.Size([64])
=> loaded checkpoint './CIFAR100/cifar100_resnet50_best.weights' (epoch -1)
epoch, neuron_units, loss, dl2_loss, top1, top5, dl2_p_acc, dl2_constraint_acc
cp: cannot stat ‘checkpoint_CIFAR100_resnet50_100_100_0.0_RobustnessDandR_eps1=7.8,_eps2=2.9__7552_107374182397200_100.000000.weights’: No such file or directory
Traceback (most recent call last):
  File "main_gc.py", line 1159, in <module>
    main()
  File "main_gc.py", line 1120, in main
    num_left, new_iter = train(args, model, device, train_loader, optimizer, epoch, criterion, oracle, test_loader_constr, test_loader_adv, print_iter, starttime, pruning_settings, train_writer=train_writer, pruning_engine=pruning_engine)
  File "main_gc.py", line 157, in train
    _, dl2_batch_loss, constr_acc = oracle.evaluate(x_batches, y_batches, None, args)
  File "/home/kduncan/Pruning/oracles.py", line 65, in evaluate
    neg_losses, pos_losses, sat, _ = self.constraint.loss(x_batches, y_batches, z_batches, args)
  File "/home/kduncan/Pruning/constraints.py", line 49, in loss
    constr = self.get_condition(z_inp, z_out, x_batches, y_batches)
  File "/home/kduncan/Pruning/constraints.py", line 352, in get_condition
    x_out1, x_out2 = self.net(x_batches[0]), self.net(x_batches[1])
  File "/home/kduncan/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/kduncan/Pruning/models/resnet.py", line 192, in forward
    x = self.layer2(x)
  File "/home/kduncan/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/kduncan/.local/lib/python3.6/site-packages/torch/nn/modules/container.py", line 92, in forward
    input = module(input)
  File "/home/kduncan/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/kduncan/Pruning/models/resnet.py", line 107, in forward
    out = self.conv3(out)
  File "/home/kduncan/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/kduncan/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 343, in forward
    return self.conv2d_forward(input, self.weight)
  File "/home/kduncan/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 340, in conv2d_forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 154.00 MiB (GPU 0; 4.63 GiB total capacity; 4.09 GiB already allocated; 153.94 MiB free; 61.14 MiB cached)
Files already downloaded and verified
Files already downloaded and verified
Ignoring network_output argument, using prob and logprob to obtain KL divergence
CIFAR100_resnet50_1_1_0.1_RobustnessDandR_eps1=7.8,_eps2=2.9__128
main_gc.py --dataset=CIFAR100 --model=resnet50 --pruning=True --tensorboard=True --log-interval=1 --pruning_config=./configs/CIFAR100_1_1.json --constraint=RobustnessDandR(eps1=7.8, eps2=2.9) --print-after-epoch=0 --dl2-weight=0.1 --delay=0 --epochs=1000 --adv-after-epoch=0 --batch-size=128 --load_model=./CIFAR100/cifar100_resnet50_best.weights --name=CIFAR100_resnet50_16
pruning_engine.load_mask(): did not find mask file, will load nothing
=> loading checkpoint './CIFAR100/cifar100_resnet50_best.weights'
conv1.weight torch.Size([64, 3, 3, 3])
bn1.weight torch.Size([64])
bn1.bias torch.Size([64])
bn1.running_mean torch.Size([64])
bn1.running_var torch.Size([64])
bn1.num_batches_tracked torch.Size([])
layer1.0.conv1.weight torch.Size([64, 64, 1, 1])
layer1.0.bn1.weight torch.Size([64])
layer1.0.bn1.bias torch.Size([64])
layer1.0.bn1.running_mean torch.Size([64])
layer1.0.bn1.running_var torch.Size([64])
*********
conv1.weight torch.Size([64, 3, 3, 3])
bn1.weight torch.Size([64])
bn1.bias torch.Size([64])
bn1.running_mean torch.Size([64])
bn1.running_var torch.Size([64])
bn1.num_batches_tracked torch.Size([])
layer1.0.conv1.weight torch.Size([64, 64, 1, 1])
layer1.0.bn1.weight torch.Size([64])
layer1.0.bn1.bias torch.Size([64])
layer1.0.bn1.running_mean torch.Size([64])
layer1.0.bn1.running_var torch.Size([64])
=> loaded checkpoint './CIFAR100/cifar100_resnet50_best.weights' (epoch -1)
epoch, neuron_units, loss, dl2_loss, top1, top5, dl2_p_acc, dl2_constraint_acc
Traceback (most recent call last):
  File "remove_header.py", line 3, in <module>
    lines = open(sys.argv[1], 'r').readlines()
FileNotFoundError: [Errno 2] No such file or directory: '../CIFAR100_resnet50_128/log_CIFAR100_resnet50_1_1_0.01_RobustnessDandR_eps1=7.8,_eps2=2.9__FGSM.txt'
/cm/local/apps/slurm/var/spool/job204740/slurm_script: line 33: files/CIFAR100_resnet50_1_1_0.01_RobustnessDandR_eps1=7.8,_eps2=2.9__FGSM.txt: No such file or directory
Traceback (most recent call last):
  File "remove_header.py", line 3, in <module>
    lines = open(sys.argv[1], 'r').readlines()
FileNotFoundError: [Errno 2] No such file or directory: '../CIFAR100_resnet50_128/log_CIFAR100_resnet50_1_1_0.1_RobustnessDandR_eps1=7.8,_eps2=2.9__FGSM.txt'

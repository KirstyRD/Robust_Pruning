Traceback (most recent call last):
  File "main_gc.py", line 1159, in <module>
    main()
  File "main_gc.py", line 1120, in main
    num_left, new_iter = train(args, model, device, train_loader, optimizer, epoch, criterion, oracle, test_loader_constr, test_loader_adv, print_iter, starttime, pruning_settings, train_writer=train_writer, pruning_engine=pruning_engine)
  File "main_gc.py", line 245, in train
    epoch, neuron_units , loss=losses, dl2_loss=dl2_batch_loss,
UnboundLocalError: local variable 'dl2_batch_loss' referenced before assignment
Files already downloaded and verified
Files already downloaded and verified
Ignoring network_output argument, using prob and logprob to obtain KL divergence
CIFAR100_resnet50_350_100_0.0_RobustnessDandR_eps1=7.8,_eps2=2.9__64
main_gc.py --dataset=CIFAR100 --model=resnet50 --pruning=True --tensorboard=True --log-interval=100 --pruning_config=./configs/CIFAR100_350_100.json --constraint=RobustnessDandR(eps1=7.8, eps2=2.9) --print-after-epoch=0 --dl2-weight=0.0 --delay=0 --epochs=1000 --adv-after-epoch=0 --batch-size=64 --load_model=./CIFAR100/cifar100_resnet50_best.weights --name=CIFAR100_resnet50_64
pruning_engine.load_mask(): did not find mask file, will load nothing
=> loading checkpoint './CIFAR100/cifar100_resnet50_best.weights'
conv1.weight torch.Size([64, 3, 3, 3])
bn1.weight torch.Size([64])
bn1.bias torch.Size([64])
bn1.running_mean torch.Size([64])
bn1.running_var torch.Size([64])
bn1.num_batches_tracked torch.Size([])
layer1.0.conv1.weight torch.Size([64, 64, 1, 1])
layer1.0.bn1.weight torch.Size([64])
layer1.0.bn1.bias torch.Size([64])
layer1.0.bn1.running_mean torch.Size([64])
layer1.0.bn1.running_var torch.Size([64])
*********
conv1.weight torch.Size([64, 3, 3, 3])
bn1.weight torch.Size([64])
bn1.bias torch.Size([64])
bn1.running_mean torch.Size([64])
bn1.running_var torch.Size([64])
bn1.num_batches_tracked torch.Size([])
layer1.0.conv1.weight torch.Size([64, 64, 1, 1])
layer1.0.bn1.weight torch.Size([64])
layer1.0.bn1.bias torch.Size([64])
layer1.0.bn1.running_mean torch.Size([64])
layer1.0.bn1.running_var torch.Size([64])
=> loaded checkpoint './CIFAR100/cifar100_resnet50_best.weights' (epoch -1)
epoch, neuron_units, loss, dl2_loss, top1, top5, dl2_p_acc, dl2_constraint_acc
Traceback (most recent call last):
  File "main_gc.py", line 1159, in <module>
    main()
  File "main_gc.py", line 1120, in main
    num_left, new_iter = train(args, model, device, train_loader, optimizer, epoch, criterion, oracle, test_loader_constr, test_loader_adv, print_iter, starttime, pruning_settings, train_writer=train_writer, pruning_engine=pruning_engine)
  File "main_gc.py", line 210, in train
    acc, _ = fgsm_test(model, device, test_loader_adv, e)
  File "main_gc.py", line 484, in fgsm_test
    final_acc = correct/float(length_testset)
ZeroDivisionError: float division by zero
Files already downloaded and verified
Files already downloaded and verified
Ignoring network_output argument, using prob and logprob to obtain KL divergence
CIFAR100_resnet50_350_100_0.05_RobustnessDandR_eps1=7.8,_eps2=2.9__64
main_gc.py --dataset=CIFAR100 --model=resnet50 --pruning=True --tensorboard=True --log-interval=100 --pruning_config=./configs/CIFAR100_350_100.json --constraint=RobustnessDandR(eps1=7.8, eps2=2.9) --print-after-epoch=0 --dl2-weight=0.05 --delay=0 --epochs=1000 --adv-after-epoch=0 --batch-size=64 --load_model=./CIFAR100/cifar100_resnet50_best.weights --name=CIFAR100_resnet50_64
pruning_engine.load_mask(): did not find mask file, will load nothing
=> loading checkpoint './CIFAR100/cifar100_resnet50_best.weights'
conv1.weight torch.Size([64, 3, 3, 3])
bn1.weight torch.Size([64])
bn1.bias torch.Size([64])
bn1.running_mean torch.Size([64])
bn1.running_var torch.Size([64])
bn1.num_batches_tracked torch.Size([])
layer1.0.conv1.weight torch.Size([64, 64, 1, 1])
layer1.0.bn1.weight torch.Size([64])
layer1.0.bn1.bias torch.Size([64])
layer1.0.bn1.running_mean torch.Size([64])
layer1.0.bn1.running_var torch.Size([64])
*********
conv1.weight torch.Size([64, 3, 3, 3])
bn1.weight torch.Size([64])
bn1.bias torch.Size([64])
bn1.running_mean torch.Size([64])
bn1.running_var torch.Size([64])
bn1.num_batches_tracked torch.Size([])
layer1.0.conv1.weight torch.Size([64, 64, 1, 1])
layer1.0.bn1.weight torch.Size([64])
layer1.0.bn1.bias torch.Size([64])
layer1.0.bn1.running_mean torch.Size([64])
layer1.0.bn1.running_var torch.Size([64])
=> loaded checkpoint './CIFAR100/cifar100_resnet50_best.weights' (epoch -1)
epoch, neuron_units, loss, dl2_loss, top1, top5, dl2_p_acc, dl2_constraint_acc
1, 7552, 11.0183, 130.2618, 15.625, 50.000, 0.000, 0.250, 100, 259.9628481864929 
1, 7202, 5.8261, 15.4484, 0.000, 3.125, 0.000, 0.875, 200, 504.4299261569977 
1, 6852, 7.8182, 198.4000, 3.125, 7.812, 0.000, 0.000, 300, 750.733381986618 
1, 6502, 5.3534, 40.9661, 0.000, 7.812, 0.000, 0.750, 400, 1000.5309343338013 
1, 6152, 9.0420, 41.6487, 1.562, 6.250, 0.000, 0.688, 500, 1252.393256187439 
1, 5802, 34.0174, 96.1443, 1.562, 3.125, 0.000, 0.500, 600, 1507.0454699993134 
1, 5452, 13.7320, 60.2275, 1.562, 9.375, 0.000, 0.688, 700, 1760.657198190689 
2, 5102, 7.3107, 70.8765, 3.125, 9.375, 0.000, 0.438, 800, 2055.340559720993 
2, 4752, 5.1039, 91.4421, 3.125, 9.375, 0.000, 0.312, 900, 2314.6617324352264 
Traceback (most recent call last):
  File "remove_header.py", line 3, in <module>
    lines = open(sys.argv[1], 'r').readlines()
FileNotFoundError: [Errno 2] No such file or directory: '../CIFAR100_resnet50_128/log_CIFAR100_resnet50_350_100_0.0_RobustnessDandR_eps1=7.8,_eps2=2.9__FGSM.txt'
/cm/local/apps/slurm/var/spool/job204748/slurm_script: line 29: files/CIFAR100_resnet50_350_100_0.0_RobustnessDandR_eps1=7.8,_eps2=2.9__FGSM.txt: No such file or directory
Traceback (most recent call last):
  File "remove_header.py", line 3, in <module>
    lines = open(sys.argv[1], 'r').readlines()
FileNotFoundError: [Errno 2] No such file or directory: '../CIFAR100_resnet50_128/log_CIFAR100_resnet50_350_100_0.05_RobustnessDandR_eps1=7.8,_eps2=2.9__FGSM.txt'

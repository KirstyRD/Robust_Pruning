Files already downloaded and verified
Files already downloaded and verified
CIFAR100_resnet50_350_100_0.1_RobustnessG_eps=0.3,_delta=0.52__64
main_gc.py --dataset=CIFAR100 --model=resnet50 --pruning=True --tensorboard=True --log-interval=100 --pruning_config=./configs/CIFAR100_350_100.json --constraint=RobustnessG(eps=0.3, delta=0.52) --print-after-epoch=0 --dl2-weight=0.1 --delay=0 --epochs=1000 --adv-after-epoch=0 --batch-size=64 --load_model=./CIFAR100/cifar100_resnet50_best.weights --name=CIFAR100_resnet50_64
pruning_engine.load_mask(): did not find mask file, will load nothing
=> loading checkpoint './CIFAR100/cifar100_resnet50_best.weights'
conv1.weight torch.Size([64, 3, 3, 3])
bn1.weight torch.Size([64])
bn1.bias torch.Size([64])
bn1.running_mean torch.Size([64])
bn1.running_var torch.Size([64])
bn1.num_batches_tracked torch.Size([])
layer1.0.conv1.weight torch.Size([64, 64, 1, 1])
layer1.0.bn1.weight torch.Size([64])
layer1.0.bn1.bias torch.Size([64])
layer1.0.bn1.running_mean torch.Size([64])
layer1.0.bn1.running_var torch.Size([64])
*********
conv1.weight torch.Size([64, 3, 3, 3])
bn1.weight torch.Size([64])
bn1.bias torch.Size([64])
bn1.running_mean torch.Size([64])
bn1.running_var torch.Size([64])
bn1.num_batches_tracked torch.Size([])
layer1.0.conv1.weight torch.Size([64, 64, 1, 1])
layer1.0.bn1.weight torch.Size([64])
layer1.0.bn1.bias torch.Size([64])
layer1.0.bn1.running_mean torch.Size([64])
layer1.0.bn1.running_var torch.Size([64])
=> loaded checkpoint './CIFAR100/cifar100_resnet50_best.weights' (epoch -1)
epoch, neuron_units, loss, dl2_loss, top1, top5, dl2_p_acc, dl2_constraint_acc
1, 7552, 0.4579, 0.3382, 85.938, 100.000, 0.000, 0.531, 100, 484.9449510574341 
1, 7202, 0.1841, 0.1326, 92.188, 100.000, 0.000, 0.781, 200, 956.1716012954712 
1, 6852, 0.7135, 0.0287, 85.938, 98.438, 0.000, 0.906, 300, 1429.1483418941498 
1, 6502, 0.4531, 0.0000, 95.312, 96.875, 0.000, 1.000, 400, 1903.9902243614197 
1, 6152, 0.5786, 0.0520, 82.812, 100.000, 0.000, 0.906, 500, 2380.669031381607 
1, 5802, 0.6743, 0.0000, 76.562, 96.875, 0.000, 1.000, 600, 2859.343587875366 
1, 5452, 1.0524, 0.0180, 71.875, 95.312, 0.000, 0.969, 700, 3339.983588695526 
2, 5102, 0.6993, 0.0490, 78.125, 95.312, 0.000, 0.875, 800, 3867.714901447296 
2, 4752, 1.1312, 0.0000, 73.438, 98.438, 0.000, 1.000, 900, 4352.4539358615875 
2, 4402, 0.9685, 0.0000, 73.438, 93.750, 0.000, 1.000, 1000, 4838.813879728317 
2, 4052, 0.9877, 0.0000, 78.125, 92.188, 0.000, 1.000, 1100, 5326.989262342453 
2, 3702, 1.0636, 0.0540, 67.188, 93.750, 0.000, 0.906, 1200, 5817.014434814453 
2, 3352, 1.1022, 0.0063, 70.312, 92.188, 0.000, 0.969, 1300, 6308.871443748474 
2, 3002, 1.1835, 0.0000, 57.812, 93.750, 0.000, 1.000, 1400, 6803.430525779724 
2, 2652, 1.7902, 0.0160, 48.438, 84.375, 0.000, 0.969, 1500, 7298.946472167969 
3, 1952, 2.2040, 0.0000, 42.188, 71.875, 0.000, 1.000, 2400, 7916.9047956466675 
3, 1602, 2.9295, 0.0040, 23.438, 57.812, 0.000, 0.906, 2500, 8416.474131584167 
3, 1252, 2.9196, 0.0186, 32.812, 62.500, 0.000, 0.844, 2600, 8917.81193113327 
3, 902, 4.4454, 0.0148, 12.500, 42.188, 0.000, 0.938, 2700, 9420.840505361557 
3, 552, 3.4213, 0.0043, 20.312, 48.438, 0.000, 0.938, 2800, 9925.69499206543 
3, 202, 6.3412, 0.0000, 0.000, 12.500, 0.000, 1.000, 2900, 10432.807696580887 
3, 0, 4.2659, 0.0000, 3.125, 23.438, 0.000, 1.000, 3000, 10940.80498123169 
Files already downloaded and verified
Files already downloaded and verified
CIFAR100_resnet50_350_100_0.05_RobustnessG_eps=0.3,_delta=0.52__64
main_gc.py --dataset=CIFAR100 --model=resnet50 --pruning=True --tensorboard=True --log-interval=100 --pruning_config=./configs/CIFAR100_350_100.json --constraint=RobustnessG(eps=0.3, delta=0.52) --print-after-epoch=0 --dl2-weight=0.05 --delay=0 --epochs=1000 --adv-after-epoch=0 --batch-size=64 --load_model=./CIFAR100/cifar100_resnet50_best.weights --name=CIFAR100_resnet50_64
pruning_engine.load_mask(): did not find mask file, will load nothing
=> loading checkpoint './CIFAR100/cifar100_resnet50_best.weights'
conv1.weight torch.Size([64, 3, 3, 3])
bn1.weight torch.Size([64])
bn1.bias torch.Size([64])
bn1.running_mean torch.Size([64])
bn1.running_var torch.Size([64])
bn1.num_batches_tracked torch.Size([])
layer1.0.conv1.weight torch.Size([64, 64, 1, 1])
layer1.0.bn1.weight torch.Size([64])
layer1.0.bn1.bias torch.Size([64])
layer1.0.bn1.running_mean torch.Size([64])
layer1.0.bn1.running_var torch.Size([64])
*********
conv1.weight torch.Size([64, 3, 3, 3])
bn1.weight torch.Size([64])
bn1.bias torch.Size([64])
bn1.running_mean torch.Size([64])
bn1.running_var torch.Size([64])
bn1.num_batches_tracked torch.Size([])
layer1.0.conv1.weight torch.Size([64, 64, 1, 1])
layer1.0.bn1.weight torch.Size([64])
layer1.0.bn1.bias torch.Size([64])
layer1.0.bn1.running_mean torch.Size([64])
layer1.0.bn1.running_var torch.Size([64])
=> loaded checkpoint './CIFAR100/cifar100_resnet50_best.weights' (epoch -1)
epoch, neuron_units, loss, dl2_loss, top1, top5, dl2_p_acc, dl2_constraint_acc
1, 7552, 0.3633, 0.5329, 85.938, 100.000, 0.000, 0.406, 100, 485.6351625919342 
1, 7202, 0.1332, 0.4949, 95.312, 100.000, 0.000, 0.562, 200, 957.2656986713409 
1, 6852, 0.6597, 0.0986, 85.938, 100.000, 0.000, 0.812, 300, 1430.3168671131134 
1, 6502, 0.4876, 0.0292, 90.625, 98.438, 0.000, 0.969, 400, 1905.970062971115 
1, 6152, 0.4846, 0.0535, 82.812, 100.000, 0.000, 0.906, 500, 2382.8516702651978 
1, 5802, 0.6409, 0.0063, 84.375, 95.312, 0.000, 0.969, 600, 2862.227051258087 
1, 5452, 0.9481, 0.0111, 73.438, 98.438, 0.000, 0.969, 700, 3343.2317893505096 
2, 5102, 0.6930, 0.0188, 73.438, 100.000, 0.000, 0.969, 800, 3870.042979955673 
2, 4752, 1.2268, 0.0048, 65.625, 96.875, 0.000, 0.969, 900, 4357.797565460205 
2, 4402, 1.1813, 0.0399, 70.312, 93.750, 0.000, 0.938, 1000, 4846.548871994019 
2, 4052, 1.0670, 0.0219, 73.438, 96.875, 0.000, 0.969, 1100, 5337.469543457031 
2, 3702, 0.8460, 0.0339, 70.312, 92.188, 0.000, 0.938, 1200, 5830.475513219833 
2, 3352, 1.0367, 0.0000, 67.188, 90.625, 0.000, 1.000, 1300, 6324.506379842758 
2, 3002, 0.9350, 0.0000, 70.312, 95.312, 0.000, 1.000, 1400, 6821.113082408905 
2, 2652, 1.6638, 0.0389, 50.000, 89.062, 0.000, 0.844, 1500, 7318.466736078262 
3, 1952, 2.5104, 0.0177, 34.375, 67.188, 0.000, 0.938, 2400, 7939.2291514873505 
3, 1602, 2.7918, 0.0261, 25.000, 68.750, 0.000, 0.812, 2500, 8440.538171291351 
3, 1252, 3.4681, 0.0220, 18.750, 51.562, 0.000, 0.812, 2600, 8945.196095466614 
3, 902, 5.9068, 0.0012, 4.688, 21.875, 0.000, 0.969, 2700, 9450.891973018646 
3, 552, 4.5814, 0.0035, 9.375, 34.375, 0.000, 0.906, 2800, 9958.374279499054 
3, 202, 4.7179, 0.0000, 4.688, 20.312, 0.000, 1.000, 2900, 10467.428552150726 
3, 0, 4.2778, 0.0001, 3.125, 25.000, 0.000, 0.969, 3000, 10979.065358877182 
Traceback (most recent call last):
  File "remove_header.py", line 3, in <module>
    lines = open(sys.argv[1], 'r').readlines()
FileNotFoundError: [Errno 2] No such file or directory: '../CIFAR100_resnet50_128/log_CIFAR100_resnet50_350_100_0.1_RobustnessG_eps=0.3,_delta=0.52__FGSM.txt'
/cm/local/apps/slurm/var/spool/job204763/slurm_script: line 29: files/CIFAR100_resnet50_350_100_0.1_RobustnessG_eps=0.3,_delta=0.52__FGSM.txt: No such file or directory
Traceback (most recent call last):
  File "remove_header.py", line 3, in <module>
    lines = open(sys.argv[1], 'r').readlines()
FileNotFoundError: [Errno 2] No such file or directory: '../CIFAR100_resnet50_128/log_CIFAR100_resnet50_350_100_0.05_RobustnessG_eps=0.3,_delta=0.52__FGSM.txt'

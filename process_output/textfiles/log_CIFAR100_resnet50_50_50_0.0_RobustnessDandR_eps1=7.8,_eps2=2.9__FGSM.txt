main_6epsilons.py --dataset=CIFAR100 --model=resnet50 --pruning=True --tensorboard=True --log-interval=50 --pruning_config=./configs/CIFAR100_50_50.json --constraint=RobustnessDandR(eps1=7.8, eps2=2.9) --print-after-epoch=0 --dl2-weight=0.0 --delay=0 --epochs=100 --adv-after-epoch=0 --batch-size=16 --load_model=./CIFAR100/models/cifar100_resnet50_best.weights --name=CIFAR100_resnet50
pruning_engine.load_mask(): did not find mask file, will load nothing
=> loading checkpoint './CIFAR100/models/cifar100_resnet50_best.weights'
conv1.weight torch.Size([64, 3, 3, 3])
bn1.weight torch.Size([64])
bn1.bias torch.Size([64])
bn1.running_mean torch.Size([64])
bn1.running_var torch.Size([64])
bn1.num_batches_tracked torch.Size([])
layer1.0.conv1.weight torch.Size([64, 64, 1, 1])
layer1.0.bn1.weight torch.Size([64])
layer1.0.bn1.bias torch.Size([64])
layer1.0.bn1.running_mean torch.Size([64])
layer1.0.bn1.running_var torch.Size([64])
*********
conv1.weight torch.Size([64, 3, 3, 3])
bn1.weight torch.Size([64])
bn1.bias torch.Size([64])
bn1.running_mean torch.Size([64])
bn1.running_var torch.Size([64])
bn1.num_batches_tracked torch.Size([])
layer1.0.conv1.weight torch.Size([64, 64, 1, 1])
layer1.0.bn1.weight torch.Size([64])
layer1.0.bn1.bias torch.Size([64])
layer1.0.bn1.running_mean torch.Size([64])
layer1.0.bn1.running_var torch.Size([64])
=> loaded checkpoint './CIFAR100/models/cifar100_resnet50_best.weights' (epoch -1)
epoch, neuron_units, loss, dl2_loss, top1, top5, dl2_p_acc, dl2_constraint_acc
1, 7552, 0.1351, 0.0878, 93.750, 100.000, 0.707, 0.987, 0.2054, 0.1716, 0.0991, 0.0748, 0.0787, 0.0513, 50, 909.8028919696808 
1, 7502, 0.2911, 0.0865, 87.500, 100.000, 0.705, 0.985, 0.1674, 0.1136, 0.0936, 0.0963, 0.0993, 0.0831, 100, 2153.421094894409 
1, 7452, 0.0605, 0.0869, 100.000, 100.000, 0.705, 0.983, 0.2297, 0.1651, 0.0828, 0.1076, 0.0909, 0.0651, 150, 3409.749425172806 
1, 7402, 0.2444, 0.0854, 87.500, 100.000, 0.706, 0.986, 0.1794, 0.1422, 0.1096, 0.0845, 0.0818, 0.0668, 200, 4589.669282674789 
1, 7352, 0.3448, 0.0876, 87.500, 100.000, 0.704, 0.983, 0.1835, 0.1461, 0.0764, 0.0843, 0.0778, 0.0717, 250, 5751.566223621368 
1, 7302, 0.1104, 0.0878, 93.750, 100.000, 0.705, 0.983, 0.2024, 0.1489, 0.1050, 0.0631, 0.0874, 0.0531, 300, 6941.7887580394745 
1, 7252, 0.3919, 0.0881, 81.250, 100.000, 0.704, 0.988, 0.1700, 0.1300, 0.1038, 0.0775, 0.0414, 0.0376, 350, 8180.170789718628 
1, 7202, 0.6040, 0.0922, 81.250, 100.000, 0.689, 0.988, 0.1966, 0.1219, 0.0957, 0.0869, 0.0716, 0.0530, 400, 9425.907233953476 
1, 7152, 0.6519, 0.0904, 81.250, 100.000, 0.690, 0.986, 0.1816, 0.1267, 0.1174, 0.0728, 0.0621, 0.0622, 450, 10584.75782752037 
1, 7102, 0.4891, 0.0875, 81.250, 100.000, 0.702, 0.987, 0.2045, 0.1458, 0.1241, 0.0924, 0.0723, 0.0746, 500, 11744.70180606842 
1, 7052, 0.3961, 0.0885, 75.000, 100.000, 0.700, 0.987, 0.2005, 0.1261, 0.1009, 0.0785, 0.0677, 0.0738, 550, 12940.083963155746 
1, 7002, 0.1553, 0.0886, 93.750, 100.000, 0.699, 0.988, 0.1943, 0.1503, 0.1187, 0.0863, 0.0726, 0.0547, 600, 14189.681396484375 
1, 6952, 0.2010, 0.0904, 93.750, 100.000, 0.695, 0.987, 0.1824, 0.1351, 0.0995, 0.0719, 0.1009, 0.0694, 650, 15435.622617959976 
1, 6902, 0.2647, 0.0918, 87.500, 100.000, 0.692, 0.985, 0.1754, 0.1370, 0.1088, 0.0890, 0.0700, 0.0571, 700, 16604.869682073593 
1, 6852, 0.2293, 0.0959, 93.750, 100.000, 0.679, 0.981, 0.1912, 0.1262, 0.1471, 0.0894, 0.0547, 0.0556, 750, 17766.520121335983 
1, 6802, 0.2927, 0.0972, 87.500, 100.000, 0.671, 0.986, 0.1971, 0.1360, 0.1021, 0.1098, 0.0979, 0.0743, 800, 18920.946648597717 
1, 6752, 0.3174, 0.0943, 93.750, 93.750, 0.683, 0.988, 0.1796, 0.1181, 0.1064, 0.0731, 0.0751, 0.0525, 850, 20113.847286701202 
1, 6702, 0.3065, 0.0966, 93.750, 100.000, 0.676, 0.986, 0.2145, 0.1671, 0.0981, 0.0902, 0.0654, 0.0852, 900, 21338.418808460236 
